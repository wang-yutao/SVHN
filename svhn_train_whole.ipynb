{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, Model, layers, optimizers, losses, metrics, datasets\n",
    "\n",
    "root_URL = 'C:\\\\Users\\\\lenovo\\\\Desktop\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape: (33401, 56, 112) (33401, 6)\n",
      "Test Shape: (13068, 56, 112) (13068, 6)\n"
     ]
    }
   ],
   "source": [
    "# 加载数据\n",
    "pickle_file = root_URL + 'svhn_dataset_112x56.pkl'\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    save = pickle.load(f)\n",
    "    train_images = save['train_images']\n",
    "    train_labels = save['train_labels']\n",
    "    test_images = save['test_images']\n",
    "    test_labels = save['test_labels']\n",
    "    del save  # hint to help gc free up memory\n",
    "    print('Train Shape:', train_images.shape, train_labels.shape)\n",
    "    print('Test Shape:', test_images.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预处理函数\n",
    "def preprocess(x, y):\n",
    "    x = tf.expand_dims(x, axis=-1) # 在axis=3扩展一维\n",
    "    y = [y[:,0],y[:,1],y[:,2],y[:,3],y[:,4],y[:,5]]\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33401, 56, 112, 1) (13068, 56, 112, 1)\n"
     ]
    }
   ],
   "source": [
    "train_images, train_labels = preprocess(train_images,train_labels)\n",
    "test_images, test_labels = preprocess(test_images,test_labels)\n",
    "print(train_images.shape,test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 5\n"
     ]
    }
   ],
   "source": [
    "print(min(train_labels[:][0]),max(train_labels[:][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inputs = Input(shape = (56,112,1))\n",
    "\n",
    "model = layers.BatchNormalization()(inputs)\n",
    "model = layers.Conv2D(64, (7,7), padding='same', activation='relu')(model)\n",
    "model = layers.MaxPool2D(pool_size=2)(model)\n",
    "\n",
    "model = layers.BatchNormalization()(model)\n",
    "model = layers.Conv2D(128, (5,5), padding='valid', activation='relu')(model)\n",
    "model = layers.MaxPool2D(pool_size=2)(model)\n",
    "\n",
    "model = layers.BatchNormalization()(model)\n",
    "model = layers.Conv2D(256, (3,3), padding='valid', activation='relu')(model)\n",
    "model = layers.MaxPool2D(pool_size=2)(model)\n",
    "model = layers.Dropout(0.5)(model)\n",
    "\n",
    "model = layers.Flatten()(model)\n",
    "# model = layers.Dense(1024, activation='relu')(model)\n",
    "model = layers.Dense(512, activation='relu')(model)\n",
    "\n",
    "output_0 = layers.Dense(6,activation='softmax')(model)\n",
    "output_1 = layers.Dense(11,activation='softmax')(model)\n",
    "output_2 = layers.Dense(11,activation='softmax')(model)\n",
    "output_3 = layers.Dense(11,activation='softmax')(model)\n",
    "output_4 = layers.Dense(11,activation='softmax')(model)\n",
    "output_5 = layers.Dense(11,activation='softmax')(model)\n",
    "\n",
    "outputs = [output_0, output_1, output_2, output_3, output_4, output_5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 56, 112, 1)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 56, 112, 1)   4           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 56, 112, 64)  3200        batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 28, 56, 64)   0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 28, 56, 64)   256         max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 24, 52, 128)  204928      batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 12, 26, 128)  0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 12, 26, 128)  512         max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 10, 24, 256)  295168      batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 5, 12, 256)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 5, 12, 256)   0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 15360)        0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          7864832     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 6)            3078        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 11)           5643        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 11)           5643        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 11)           5643        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 11)           5643        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 11)           5643        dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 8,400,193\n",
      "Trainable params: 8,399,807\n",
      "Non-trainable params: 386\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=\"rmsprop\",\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置回调功能\n",
    "filepath = 'my_model_whole.h5' # 保存模型地址\n",
    "saved_model = tf.keras.callbacks.ModelCheckpoint(filepath, verbose = 1) # 回调保存模型功能\n",
    "tensorboard = tf.keras.callbacks.TensorBoard() # 回调可视化数据功能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 26720 samples, validate on 6681 samples\n",
      "Epoch 1/100\n",
      "    4/26720 [..............................] - ETA: 6:32:29 - loss: 26.9650 - dense_1_loss: 1.9908 - dense_2_loss: 4.5242 - dense_3_loss: 4.3686 - dense_4_loss: 3.3712 - dense_5_loss: 6.2720 - dense_6_loss: 6.4382 - dense_1_accuracy: 0.2500 - dense_2_accuracy: 0.0000e+00 - dense_3_accuracy: 0.2500 - dense_4_accuracy: 0.0000e+00 - dense_5_accuracy: 0.0000e+00 - dense_6_accuracy: 0.0000e+00WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.123932). Check your callbacks.\n",
      "26716/26720 [============================>.] - ETA: 0s - loss: 6.8626 - dense_1_loss: 0.9756 - dense_2_loss: 1.9578 - dense_3_loss: 2.2405 - dense_4_loss: 1.3296 - dense_5_loss: 0.3510 - dense_6_loss: 0.0080 - dense_1_accuracy: 0.6146 - dense_2_accuracy: 0.3420 - dense_3_accuracy: 0.2400 - dense_4_accuracy: 0.6937 - dense_5_accuracy: 0.9571 - dense_6_accuracy: 0.9996\n",
      "Epoch 00001: saving model to my_model_whole.h5\n",
      "26720/26720 [==============================] - 243s 9ms/sample - loss: 6.8622 - dense_1_loss: 0.9755 - dense_2_loss: 1.9578 - dense_3_loss: 2.2404 - dense_4_loss: 1.3294 - dense_5_loss: 0.3510 - dense_6_loss: 0.0080 - dense_1_accuracy: 0.6146 - dense_2_accuracy: 0.3420 - dense_3_accuracy: 0.2400 - dense_4_accuracy: 0.6938 - dense_5_accuracy: 0.9571 - dense_6_accuracy: 0.9996 - val_loss: 5.7392 - val_dense_1_loss: 0.7516 - val_dense_2_loss: 1.6306 - val_dense_3_loss: 1.9029 - val_dense_4_loss: 1.1333 - val_dense_5_loss: 0.3199 - val_dense_6_loss: 0.0019 - val_dense_1_accuracy: 0.7008 - val_dense_2_accuracy: 0.4565 - val_dense_3_accuracy: 0.3550 - val_dense_4_accuracy: 0.7030 - val_dense_5_accuracy: 0.9543 - val_dense_6_accuracy: 0.9999\n",
      "Epoch 2/100\n",
      "26716/26720 [============================>.] - ETA: 0s - loss: 5.9408 - dense_1_loss: 0.8090 - dense_2_loss: 1.6162 - dense_3_loss: 1.9527 - dense_4_loss: 1.2149 - dense_5_loss: 0.3401 - dense_6_loss: 0.0079 - dense_1_accuracy: 0.6870 - dense_2_accuracy: 0.4632 - dense_3_accuracy: 0.3433 - dense_4_accuracy: 0.6956 - dense_5_accuracy: 0.9574 - dense_6_accuracy: 0.9997\n",
      "Epoch 00002: saving model to my_model_whole.h5\n",
      "26720/26720 [==============================] - 243s 9ms/sample - loss: 5.9408 - dense_1_loss: 0.8090 - dense_2_loss: 1.6163 - dense_3_loss: 1.9528 - dense_4_loss: 1.2148 - dense_5_loss: 0.3401 - dense_6_loss: 0.0079 - dense_1_accuracy: 0.6870 - dense_2_accuracy: 0.4631 - dense_3_accuracy: 0.3432 - dense_4_accuracy: 0.6957 - dense_5_accuracy: 0.9574 - dense_6_accuracy: 0.9997 - val_loss: 5.6156 - val_dense_1_loss: 0.7580 - val_dense_2_loss: 1.4757 - val_dense_3_loss: 1.8339 - val_dense_4_loss: 1.2156 - val_dense_5_loss: 0.3287 - val_dense_6_loss: 0.0041 - val_dense_1_accuracy: 0.6795 - val_dense_2_accuracy: 0.5246 - val_dense_3_accuracy: 0.4013 - val_dense_4_accuracy: 0.6936 - val_dense_5_accuracy: 0.9543 - val_dense_6_accuracy: 0.9999\n",
      "Epoch 3/100\n",
      "26712/26720 [============================>.] - ETA: 0s - loss: 5.6326 - dense_1_loss: 0.7700 - dense_2_loss: 1.5061 - dense_3_loss: 1.8413 - dense_4_loss: 1.1712 - dense_5_loss: 0.3354 - dense_6_loss: 0.0086 - dense_1_accuracy: 0.7099 - dense_2_accuracy: 0.5041 - dense_3_accuracy: 0.3891 - dense_4_accuracy: 0.7016 - dense_5_accuracy: 0.9574 - dense_6_accuracy: 0.9997\n",
      "Epoch 00003: saving model to my_model_whole.h5\n",
      "26720/26720 [==============================] - 239s 9ms/sample - loss: 5.6323 - dense_1_loss: 0.7699 - dense_2_loss: 1.5062 - dense_3_loss: 1.8413 - dense_4_loss: 1.1710 - dense_5_loss: 0.3353 - dense_6_loss: 0.0086 - dense_1_accuracy: 0.7100 - dense_2_accuracy: 0.5040 - dense_3_accuracy: 0.3890 - dense_4_accuracy: 0.7016 - dense_5_accuracy: 0.9574 - dense_6_accuracy: 0.9997 - val_loss: 5.2047 - val_dense_1_loss: 0.6945 - val_dense_2_loss: 1.3428 - val_dense_3_loss: 1.6875 - val_dense_4_loss: 1.1009 - val_dense_5_loss: 0.3748 - val_dense_6_loss: 0.0045 - val_dense_1_accuracy: 0.7334 - val_dense_2_accuracy: 0.5767 - val_dense_3_accuracy: 0.4598 - val_dense_4_accuracy: 0.7033 - val_dense_5_accuracy: 0.9543 - val_dense_6_accuracy: 0.9999\n",
      "Epoch 4/100\n",
      "26712/26720 [============================>.] - ETA: 0s - loss: 5.4707 - dense_1_loss: 0.7487 - dense_2_loss: 1.4483 - dense_3_loss: 1.8061 - dense_4_loss: 1.1346 - dense_5_loss: 0.3254 - dense_6_loss: 0.0075 - dense_1_accuracy: 0.7219 - dense_2_accuracy: 0.5249 - dense_3_accuracy: 0.4023 - dense_4_accuracy: 0.7060 - dense_5_accuracy: 0.9574 - dense_6_accuracy: 0.9997\n",
      "Epoch 00004: saving model to my_model_whole.h5\n",
      "26720/26720 [==============================] - 239s 9ms/sample - loss: 5.4709 - dense_1_loss: 0.7488 - dense_2_loss: 1.4484 - dense_3_loss: 1.8062 - dense_4_loss: 1.1347 - dense_5_loss: 0.3254 - dense_6_loss: 0.0075 - dense_1_accuracy: 0.7219 - dense_2_accuracy: 0.5249 - dense_3_accuracy: 0.4024 - dense_4_accuracy: 0.7060 - dense_5_accuracy: 0.9574 - dense_6_accuracy: 0.9997 - val_loss: 5.0077 - val_dense_1_loss: 0.6485 - val_dense_2_loss: 1.3461 - val_dense_3_loss: 1.7142 - val_dense_4_loss: 1.0283 - val_dense_5_loss: 0.2679 - val_dense_6_loss: 0.0031 - val_dense_1_accuracy: 0.7629 - val_dense_2_accuracy: 0.5667 - val_dense_3_accuracy: 0.4324 - val_dense_4_accuracy: 0.7140 - val_dense_5_accuracy: 0.9543 - val_dense_6_accuracy: 0.9999\n",
      "Epoch 5/100\n",
      "26712/26720 [============================>.] - ETA: 0s - loss: 5.4854 - dense_1_loss: 0.7517 - dense_2_loss: 1.4667 - dense_3_loss: 1.8103 - dense_4_loss: 1.1284 - dense_5_loss: 0.3204 - dense_6_loss: 0.0079 - dense_1_accuracy: 0.7258 - dense_2_accuracy: 0.5189 - dense_3_accuracy: 0.4076 - dense_4_accuracy: 0.7078 - dense_5_accuracy: 0.9575 - dense_6_accuracy: 0.9997\n",
      "Epoch 00005: saving model to my_model_whole.h5\n",
      "26720/26720 [==============================] - 241s 9ms/sample - loss: 5.4855 - dense_1_loss: 0.7517 - dense_2_loss: 1.4666 - dense_3_loss: 1.8103 - dense_4_loss: 1.1283 - dense_5_loss: 0.3207 - dense_6_loss: 0.0079 - dense_1_accuracy: 0.7258 - dense_2_accuracy: 0.5189 - dense_3_accuracy: 0.4076 - dense_4_accuracy: 0.7078 - dense_5_accuracy: 0.9574 - dense_6_accuracy: 0.9997 - val_loss: 5.3626 - val_dense_1_loss: 0.7316 - val_dense_2_loss: 1.4846 - val_dense_3_loss: 1.8303 - val_dense_4_loss: 1.0836 - val_dense_5_loss: 0.2303 - val_dense_6_loss: 0.0030 - val_dense_1_accuracy: 0.7339 - val_dense_2_accuracy: 0.5135 - val_dense_3_accuracy: 0.4047 - val_dense_4_accuracy: 0.7035 - val_dense_5_accuracy: 0.9543 - val_dense_6_accuracy: 0.9999\n",
      "Epoch 6/100\n",
      "26716/26720 [============================>.] - ETA: 0s - loss: 5.4764 - dense_1_loss: 0.7523 - dense_2_loss: 1.4641 - dense_3_loss: 1.8197 - dense_4_loss: 1.1282 - dense_5_loss: 0.3034 - dense_6_loss: 0.0087 - dense_1_accuracy: 0.7295 - dense_2_accuracy: 0.5252 - dense_3_accuracy: 0.4087 - dense_4_accuracy: 0.7070 - dense_5_accuracy: 0.9574 - dense_6_accuracy: 0.9997\n",
      "Epoch 00006: saving model to my_model_whole.h5\n",
      "26720/26720 [==============================] - 241s 9ms/sample - loss: 5.4775 - dense_1_loss: 0.7525 - dense_2_loss: 1.4642 - dense_3_loss: 1.8199 - dense_4_loss: 1.1288 - dense_5_loss: 0.3033 - dense_6_loss: 0.0087 - dense_1_accuracy: 0.7295 - dense_2_accuracy: 0.5252 - dense_3_accuracy: 0.4087 - dense_4_accuracy: 0.7069 - dense_5_accuracy: 0.9574 - dense_6_accuracy: 0.9997 - val_loss: 5.5199 - val_dense_1_loss: 0.7612 - val_dense_2_loss: 1.5404 - val_dense_3_loss: 1.8669 - val_dense_4_loss: 1.0954 - val_dense_5_loss: 0.2544 - val_dense_6_loss: 0.0028 - val_dense_1_accuracy: 0.7252 - val_dense_2_accuracy: 0.4974 - val_dense_3_accuracy: 0.3859 - val_dense_4_accuracy: 0.7033 - val_dense_5_accuracy: 0.9543 - val_dense_6_accuracy: 0.9999\n",
      "Epoch 7/100\n",
      "26716/26720 [============================>.] - ETA: 0s - loss: 5.5621 - dense_1_loss: 0.7794 - dense_2_loss: 1.4770 - dense_3_loss: 1.8421 - dense_4_loss: 1.1385 - dense_5_loss: 0.3167 - dense_6_loss: 0.0084 - dense_1_accuracy: 0.7209 - dense_2_accuracy: 0.5228 - dense_3_accuracy: 0.4063 - dense_4_accuracy: 0.7087 - dense_5_accuracy: 0.9573 - dense_6_accuracy: 0.9997\n",
      "Epoch 00007: saving model to my_model_whole.h5\n",
      "26720/26720 [==============================] - 242s 9ms/sample - loss: 5.5619 - dense_1_loss: 0.7793 - dense_2_loss: 1.4771 - dense_3_loss: 1.8420 - dense_4_loss: 1.1384 - dense_5_loss: 0.3167 - dense_6_loss: 0.0084 - dense_1_accuracy: 0.7209 - dense_2_accuracy: 0.5228 - dense_3_accuracy: 0.4064 - dense_4_accuracy: 0.7088 - dense_5_accuracy: 0.9573 - dense_6_accuracy: 0.9997 - val_loss: 5.2671 - val_dense_1_loss: 0.7172 - val_dense_2_loss: 1.4365 - val_dense_3_loss: 1.7395 - val_dense_4_loss: 1.0959 - val_dense_5_loss: 0.2747 - val_dense_6_loss: 0.0039 - val_dense_1_accuracy: 0.7256 - val_dense_2_accuracy: 0.5245 - val_dense_3_accuracy: 0.4272 - val_dense_4_accuracy: 0.7075 - val_dense_5_accuracy: 0.9542 - val_dense_6_accuracy: 0.9999\n",
      "Epoch 8/100\n",
      "26712/26720 [============================>.] - ETA: 0s - loss: 5.6682 - dense_1_loss: 0.7905 - dense_2_loss: 1.5105 - dense_3_loss: 1.8875 - dense_4_loss: 1.1546 - dense_5_loss: 0.3171 - dense_6_loss: 0.0080 - dense_1_accuracy: 0.7129 - dense_2_accuracy: 0.5131 - dense_3_accuracy: 0.3893 - dense_4_accuracy: 0.7057 - dense_5_accuracy: 0.9575 - dense_6_accuracy: 0.9997\n",
      "Epoch 00008: saving model to my_model_whole.h5\n",
      "26720/26720 [==============================] - 242s 9ms/sample - loss: 5.6688 - dense_1_loss: 0.7906 - dense_2_loss: 1.5103 - dense_3_loss: 1.8880 - dense_4_loss: 1.1547 - dense_5_loss: 0.3173 - dense_6_loss: 0.0080 - dense_1_accuracy: 0.7129 - dense_2_accuracy: 0.5132 - dense_3_accuracy: 0.3892 - dense_4_accuracy: 0.7057 - dense_5_accuracy: 0.9575 - dense_6_accuracy: 0.9997 - val_loss: 5.4016 - val_dense_1_loss: 0.7325 - val_dense_2_loss: 1.4638 - val_dense_3_loss: 1.8239 - val_dense_4_loss: 1.1111 - val_dense_5_loss: 0.2667 - val_dense_6_loss: 0.0041 - val_dense_1_accuracy: 0.7183 - val_dense_2_accuracy: 0.5203 - val_dense_3_accuracy: 0.4053 - val_dense_4_accuracy: 0.7093 - val_dense_5_accuracy: 0.9551 - val_dense_6_accuracy: 0.9999\n",
      "Epoch 9/100\n",
      "26716/26720 [============================>.] - ETA: 0s - loss: 5.7962 - dense_1_loss: 0.8173 - dense_2_loss: 1.5502 - dense_3_loss: 1.9156 - dense_4_loss: 1.1719 - dense_5_loss: 0.3324 - dense_6_loss: 0.0087 - dense_1_accuracy: 0.7021 - dense_2_accuracy: 0.4993 - dense_3_accuracy: 0.3840 - dense_4_accuracy: 0.7041 - dense_5_accuracy: 0.9574 - dense_6_accuracy: 0.9997\n",
      "Epoch 00009: saving model to my_model_whole.h5\n",
      "26720/26720 [==============================] - 243s 9ms/sample - loss: 5.7957 - dense_1_loss: 0.8172 - dense_2_loss: 1.5501 - dense_3_loss: 1.9155 - dense_4_loss: 1.1717 - dense_5_loss: 0.3324 - dense_6_loss: 0.0087 - dense_1_accuracy: 0.7022 - dense_2_accuracy: 0.4993 - dense_3_accuracy: 0.3841 - dense_4_accuracy: 0.7042 - dense_5_accuracy: 0.9574 - dense_6_accuracy: 0.9997 - val_loss: 5.1162 - val_dense_1_loss: 0.6646 - val_dense_2_loss: 1.3328 - val_dense_3_loss: 1.6745 - val_dense_4_loss: 1.0287 - val_dense_5_loss: 0.4126 - val_dense_6_loss: 0.0046 - val_dense_1_accuracy: 0.7723 - val_dense_2_accuracy: 0.5811 - val_dense_3_accuracy: 0.4368 - val_dense_4_accuracy: 0.7153 - val_dense_5_accuracy: 0.9549 - val_dense_6_accuracy: 0.9999\n",
      "Epoch 10/100\n",
      "26716/26720 [============================>.] - ETA: 0s - loss: 5.8788 - dense_1_loss: 0.8271 - dense_2_loss: 1.5715 - dense_3_loss: 1.9410 - dense_4_loss: 1.1793 - dense_5_loss: 0.3510 - dense_6_loss: 0.0090 - dense_1_accuracy: 0.7061 - dense_2_accuracy: 0.4939 - dense_3_accuracy: 0.3733 - dense_4_accuracy: 0.7024 - dense_5_accuracy: 0.9574 - dense_6_accuracy: 0.9997\n",
      "Epoch 00010: saving model to my_model_whole.h5\n",
      "26720/26720 [==============================] - 242s 9ms/sample - loss: 5.8786 - dense_1_loss: 0.8271 - dense_2_loss: 1.5713 - dense_3_loss: 1.9410 - dense_4_loss: 1.1794 - dense_5_loss: 0.3509 - dense_6_loss: 0.0090 - dense_1_accuracy: 0.7061 - dense_2_accuracy: 0.4939 - dense_3_accuracy: 0.3734 - dense_4_accuracy: 0.7024 - dense_5_accuracy: 0.9574 - dense_6_accuracy: 0.9997 - val_loss: 5.0976 - val_dense_1_loss: 0.6630 - val_dense_2_loss: 1.3976 - val_dense_3_loss: 1.7250 - val_dense_4_loss: 1.0388 - val_dense_5_loss: 0.2703 - val_dense_6_loss: 0.0042 - val_dense_1_accuracy: 0.7533 - val_dense_2_accuracy: 0.5528 - val_dense_3_accuracy: 0.4216 - val_dense_4_accuracy: 0.7057 - val_dense_5_accuracy: 0.9548 - val_dense_6_accuracy: 0.9999\n",
      "Epoch 11/100\n",
      "26712/26720 [============================>.] - ETA: 0s - loss: 6.0264 - dense_1_loss: 0.8564 - dense_2_loss: 1.6338 - dense_3_loss: 1.9714 - dense_4_loss: 1.2104 - dense_5_loss: 0.3467 - dense_6_loss: 0.0076 - dense_1_accuracy: 0.6917 - dense_2_accuracy: 0.4796 - dense_3_accuracy: 0.3555 - dense_4_accuracy: 0.7026 - dense_5_accuracy: 0.9574 - dense_6_accuracy: 0.9997\n",
      "Epoch 00011: saving model to my_model_whole.h5\n",
      "26720/26720 [==============================] - 243s 9ms/sample - loss: 6.0260 - dense_1_loss: 0.8564 - dense_2_loss: 1.6339 - dense_3_loss: 1.9714 - dense_4_loss: 1.2101 - dense_5_loss: 0.3466 - dense_6_loss: 0.0076 - dense_1_accuracy: 0.6918 - dense_2_accuracy: 0.4796 - dense_3_accuracy: 0.3555 - dense_4_accuracy: 0.7027 - dense_5_accuracy: 0.9574 - dense_6_accuracy: 0.9997 - val_loss: 6.4774 - val_dense_1_loss: 0.9601 - val_dense_2_loss: 1.7478 - val_dense_3_loss: 2.0898 - val_dense_4_loss: 1.3029 - val_dense_5_loss: 0.3750 - val_dense_6_loss: 0.0034 - val_dense_1_accuracy: 0.6215 - val_dense_2_accuracy: 0.3839 - val_dense_3_accuracy: 0.2474 - val_dense_4_accuracy: 0.6993 - val_dense_5_accuracy: 0.9543 - val_dense_6_accuracy: 0.9999\n",
      "Epoch 12/100\n",
      "26716/26720 [============================>.] - ETA: 0s - loss: 6.1217 - dense_1_loss: 0.8643 - dense_2_loss: 1.6812 - dense_3_loss: 2.0106 - dense_4_loss: 1.2171 - dense_5_loss: 0.3404 - dense_6_loss: 0.0083 - dense_1_accuracy: 0.6848 - dense_2_accuracy: 0.4592 - dense_3_accuracy: 0.3426 - dense_4_accuracy: 0.7013 - dense_5_accuracy: 0.9573 - dense_6_accuracy: 0.9997\n",
      "Epoch 00012: saving model to my_model_whole.h5\n",
      "26720/26720 [==============================] - 246s 9ms/sample - loss: 6.1217 - dense_1_loss: 0.8642 - dense_2_loss: 1.6812 - dense_3_loss: 2.0106 - dense_4_loss: 1.2172 - dense_5_loss: 0.3403 - dense_6_loss: 0.0083 - dense_1_accuracy: 0.6848 - dense_2_accuracy: 0.4592 - dense_3_accuracy: 0.3426 - dense_4_accuracy: 0.7013 - dense_5_accuracy: 0.9573 - dense_6_accuracy: 0.9997 - val_loss: 5.7355 - val_dense_1_loss: 0.7902 - val_dense_2_loss: 1.5606 - val_dense_3_loss: 1.9265 - val_dense_4_loss: 1.1644 - val_dense_5_loss: 0.2909 - val_dense_6_loss: 0.0038 - val_dense_1_accuracy: 0.7104 - val_dense_2_accuracy: 0.4880 - val_dense_3_accuracy: 0.3601 - val_dense_4_accuracy: 0.7021 - val_dense_5_accuracy: 0.9543 - val_dense_6_accuracy: 0.9999\n",
      "Epoch 13/100\n",
      "26712/26720 [============================>.] - ETA: 0s - loss: 6.2513 - dense_1_loss: 0.8877 - dense_2_loss: 1.7236 - dense_3_loss: 2.0476 - dense_4_loss: 1.2454 - dense_5_loss: 0.3395 - dense_6_loss: 0.0075 - dense_1_accuracy: 0.6761 - dense_2_accuracy: 0.4440 - dense_3_accuracy: 0.3249 - dense_4_accuracy: 0.6981 - dense_5_accuracy: 0.9573 - dense_6_accuracy: 0.9997\n",
      "Epoch 00013: saving model to my_model_whole.h5\n",
      "26720/26720 [==============================] - 242s 9ms/sample - loss: 6.2520 - dense_1_loss: 0.8877 - dense_2_loss: 1.7242 - dense_3_loss: 2.0476 - dense_4_loss: 1.2456 - dense_5_loss: 0.3394 - dense_6_loss: 0.0075 - dense_1_accuracy: 0.6762 - dense_2_accuracy: 0.4441 - dense_3_accuracy: 0.3249 - dense_4_accuracy: 0.6980 - dense_5_accuracy: 0.9573 - dense_6_accuracy: 0.9997 - val_loss: 5.7821 - val_dense_1_loss: 0.7759 - val_dense_2_loss: 1.6131 - val_dense_3_loss: 1.9176 - val_dense_4_loss: 1.1483 - val_dense_5_loss: 0.3234 - val_dense_6_loss: 0.0045 - val_dense_1_accuracy: 0.7104 - val_dense_2_accuracy: 0.4731 - val_dense_3_accuracy: 0.3488 - val_dense_4_accuracy: 0.7009 - val_dense_5_accuracy: 0.9543 - val_dense_6_accuracy: 0.9999\n",
      "Epoch 14/100\n",
      "26716/26720 [============================>.] - ETA: 0s - loss: 6.3661 - dense_1_loss: 0.9041 - dense_2_loss: 1.7657 - dense_3_loss: 2.1006 - dense_4_loss: 1.2491 - dense_5_loss: 0.3387 - dense_6_loss: 0.0080 - dense_1_accuracy: 0.6650 - dense_2_accuracy: 0.4253 - dense_3_accuracy: 0.3072 - dense_4_accuracy: 0.6988 - dense_5_accuracy: 0.9574 - dense_6_accuracy: 0.9997\n",
      "Epoch 00014: saving model to my_model_whole.h5\n",
      "26720/26720 [==============================] - 244s 9ms/sample - loss: 6.3660 - dense_1_loss: 0.9041 - dense_2_loss: 1.7658 - dense_3_loss: 2.1005 - dense_4_loss: 1.2490 - dense_5_loss: 0.3386 - dense_6_loss: 0.0080 - dense_1_accuracy: 0.6650 - dense_2_accuracy: 0.4252 - dense_3_accuracy: 0.3072 - dense_4_accuracy: 0.6988 - dense_5_accuracy: 0.9574 - dense_6_accuracy: 0.9997 - val_loss: 6.1189 - val_dense_1_loss: 0.8615 - val_dense_2_loss: 1.6819 - val_dense_3_loss: 2.0222 - val_dense_4_loss: 1.2605 - val_dense_5_loss: 0.2896 - val_dense_6_loss: 0.0041 - val_dense_1_accuracy: 0.6553 - val_dense_2_accuracy: 0.4258 - val_dense_3_accuracy: 0.3065 - val_dense_4_accuracy: 0.6969 - val_dense_5_accuracy: 0.9543 - val_dense_6_accuracy: 0.9999\n",
      "Epoch 15/100\n",
      "26716/26720 [============================>.] - ETA: 0s - loss: 6.5004 - dense_1_loss: 0.9283 - dense_2_loss: 1.8205 - dense_3_loss: 2.1252 - dense_4_loss: 1.2799 - dense_5_loss: 0.3387 - dense_6_loss: 0.0078 - dense_1_accuracy: 0.6443 - dense_2_accuracy: 0.4033 - dense_3_accuracy: 0.2911 - dense_4_accuracy: 0.6980 - dense_5_accuracy: 0.9573 - dense_6_accuracy: 0.9997\n",
      "Epoch 00015: saving model to my_model_whole.h5\n",
      "26720/26720 [==============================] - 244s 9ms/sample - loss: 6.5006 - dense_1_loss: 0.9283 - dense_2_loss: 1.8204 - dense_3_loss: 2.1251 - dense_4_loss: 1.2802 - dense_5_loss: 0.3388 - dense_6_loss: 0.0078 - dense_1_accuracy: 0.6442 - dense_2_accuracy: 0.4033 - dense_3_accuracy: 0.2911 - dense_4_accuracy: 0.6979 - dense_5_accuracy: 0.9572 - dense_6_accuracy: 0.9997 - val_loss: 6.2438 - val_dense_1_loss: 0.8663 - val_dense_2_loss: 1.6327 - val_dense_3_loss: 1.9598 - val_dense_4_loss: 1.2921 - val_dense_5_loss: 0.4894 - val_dense_6_loss: 0.0042 - val_dense_1_accuracy: 0.7137 - val_dense_2_accuracy: 0.4728 - val_dense_3_accuracy: 0.3660 - val_dense_4_accuracy: 0.7035 - val_dense_5_accuracy: 0.9543 - val_dense_6_accuracy: 0.9999\n",
      "Epoch 16/100\n",
      "26712/26720 [============================>.] - ETA: 0s - loss: 6.5637 - dense_1_loss: 0.9397 - dense_2_loss: 1.8560 - dense_3_loss: 2.1568 - dense_4_loss: 1.2583 - dense_5_loss: 0.3446 - dense_6_loss: 0.0084 - dense_1_accuracy: 0.6482 - dense_2_accuracy: 0.3920 - dense_3_accuracy: 0.2815 - dense_4_accuracy: 0.6986 - dense_5_accuracy: 0.9574 - dense_6_accuracy: 0.9997\n",
      "Epoch 00016: saving model to my_model_whole.h5\n",
      "26720/26720 [==============================] - 245s 9ms/sample - loss: 6.5637 - dense_1_loss: 0.9397 - dense_2_loss: 1.8560 - dense_3_loss: 2.1568 - dense_4_loss: 1.2581 - dense_5_loss: 0.3448 - dense_6_loss: 0.0084 - dense_1_accuracy: 0.6482 - dense_2_accuracy: 0.3920 - dense_3_accuracy: 0.2815 - dense_4_accuracy: 0.6987 - dense_5_accuracy: 0.9573 - dense_6_accuracy: 0.9997 - val_loss: 6.1592 - val_dense_1_loss: 0.8521 - val_dense_2_loss: 1.7634 - val_dense_3_loss: 2.0962 - val_dense_4_loss: 1.1711 - val_dense_5_loss: 0.2729 - val_dense_6_loss: 0.0041 - val_dense_1_accuracy: 0.6569 - val_dense_2_accuracy: 0.3742 - val_dense_3_accuracy: 0.2733 - val_dense_4_accuracy: 0.6969 - val_dense_5_accuracy: 0.9543 - val_dense_6_accuracy: 0.9999\n",
      "Epoch 17/100\n",
      "26716/26720 [============================>.] - ETA: 0s - loss: 6.5907 - dense_1_loss: 0.9411 - dense_2_loss: 1.8688 - dense_3_loss: 2.1916 - dense_4_loss: 1.2651 - dense_5_loss: 0.3159 - dense_6_loss: 0.0081 - dense_1_accuracy: 0.6378 - dense_2_accuracy: 0.3802 - dense_3_accuracy: 0.2671 - dense_4_accuracy: 0.6988 - dense_5_accuracy: 0.9573 - dense_6_accuracy: 0.9997\n",
      "Epoch 00017: saving model to my_model_whole.h5\n",
      "26720/26720 [==============================] - 245s 9ms/sample - loss: 6.5903 - dense_1_loss: 0.9411 - dense_2_loss: 1.8687 - dense_3_loss: 2.1914 - dense_4_loss: 1.2651 - dense_5_loss: 0.3159 - dense_6_loss: 0.0081 - dense_1_accuracy: 0.6378 - dense_2_accuracy: 0.3802 - dense_3_accuracy: 0.2672 - dense_4_accuracy: 0.6988 - dense_5_accuracy: 0.9573 - dense_6_accuracy: 0.9997 - val_loss: 5.9693 - val_dense_1_loss: 0.8344 - val_dense_2_loss: 1.6213 - val_dense_3_loss: 1.9796 - val_dense_4_loss: 1.2188 - val_dense_5_loss: 0.3123 - val_dense_6_loss: 0.0047 - val_dense_1_accuracy: 0.6830 - val_dense_2_accuracy: 0.4487 - val_dense_3_accuracy: 0.3359 - val_dense_4_accuracy: 0.7002 - val_dense_5_accuracy: 0.9545 - val_dense_6_accuracy: 0.9999\n",
      "Epoch 18/100\n",
      "26716/26720 [============================>.] - ETA: 0s - loss: 6.7058 - dense_1_loss: 0.9514 - dense_2_loss: 1.9233 - dense_3_loss: 2.2286 - dense_4_loss: 1.2738 - dense_5_loss: 0.3205 - dense_6_loss: 0.0082 - dense_1_accuracy: 0.6335 - dense_2_accuracy: 0.3628 - dense_3_accuracy: 0.2526 - dense_4_accuracy: 0.6965 - dense_5_accuracy: 0.9573 - dense_6_accuracy: 0.9997\n",
      "Epoch 00018: saving model to my_model_whole.h5\n",
      "26720/26720 [==============================] - 246s 9ms/sample - loss: 6.7060 - dense_1_loss: 0.9514 - dense_2_loss: 1.9234 - dense_3_loss: 2.2285 - dense_4_loss: 1.2738 - dense_5_loss: 0.3208 - dense_6_loss: 0.0082 - dense_1_accuracy: 0.6335 - dense_2_accuracy: 0.3627 - dense_3_accuracy: 0.2526 - dense_4_accuracy: 0.6965 - dense_5_accuracy: 0.9572 - dense_6_accuracy: 0.9997 - val_loss: 6.0108 - val_dense_1_loss: 0.7522 - val_dense_2_loss: 1.8050 - val_dense_3_loss: 2.0764 - val_dense_4_loss: 1.1078 - val_dense_5_loss: 0.2649 - val_dense_6_loss: 0.0049 - val_dense_1_accuracy: 0.6929 - val_dense_2_accuracy: 0.3717 - val_dense_3_accuracy: 0.2687 - val_dense_4_accuracy: 0.6979 - val_dense_5_accuracy: 0.9545 - val_dense_6_accuracy: 0.9999\n",
      "Epoch 19/100\n",
      "26712/26720 [============================>.] - ETA: 0s - loss: 6.6611 - dense_1_loss: 0.9349 - dense_2_loss: 1.9238 - dense_3_loss: 2.2282 - dense_4_loss: 1.2466 - dense_5_loss: 0.3197 - dense_6_loss: 0.0081 - dense_1_accuracy: 0.6444 - dense_2_accuracy: 0.3579 - dense_3_accuracy: 0.2507 - dense_4_accuracy: 0.6977 - dense_5_accuracy: 0.9574 - dense_6_accuracy: 0.9997\n",
      "Epoch 00019: saving model to my_model_whole.h5\n",
      "26720/26720 [==============================] - 246s 9ms/sample - loss: 6.6618 - dense_1_loss: 0.9350 - dense_2_loss: 1.9238 - dense_3_loss: 2.2282 - dense_4_loss: 1.2470 - dense_5_loss: 0.3198 - dense_6_loss: 0.0081 - dense_1_accuracy: 0.6443 - dense_2_accuracy: 0.3578 - dense_3_accuracy: 0.2507 - dense_4_accuracy: 0.6976 - dense_5_accuracy: 0.9574 - dense_6_accuracy: 0.9997 - val_loss: 6.3764 - val_dense_1_loss: 0.8709 - val_dense_2_loss: 1.8553 - val_dense_3_loss: 2.1842 - val_dense_4_loss: 1.1713 - val_dense_5_loss: 0.2912 - val_dense_6_loss: 0.0039 - val_dense_1_accuracy: 0.6486 - val_dense_2_accuracy: 0.3393 - val_dense_3_accuracy: 0.2332 - val_dense_4_accuracy: 0.6969 - val_dense_5_accuracy: 0.9543 - val_dense_6_accuracy: 0.9999\n",
      "Epoch 20/100\n",
      "26716/26720 [============================>.] - ETA: 0s - loss: 6.6606 - dense_1_loss: 0.9285 - dense_2_loss: 1.9167 - dense_3_loss: 2.2210 - dense_4_loss: 1.2565 - dense_5_loss: 0.3288 - dense_6_loss: 0.0091 - dense_1_accuracy: 0.6515 - dense_2_accuracy: 0.3573 - dense_3_accuracy: 0.2461 - dense_4_accuracy: 0.6979 - dense_5_accuracy: 0.9572 - dense_6_accuracy: 0.9997\n",
      "Epoch 00020: saving model to my_model_whole.h5\n",
      "26720/26720 [==============================] - 246s 9ms/sample - loss: 6.6607 - dense_1_loss: 0.9285 - dense_2_loss: 1.9167 - dense_3_loss: 2.2211 - dense_4_loss: 1.2566 - dense_5_loss: 0.3288 - dense_6_loss: 0.0091 - dense_1_accuracy: 0.6515 - dense_2_accuracy: 0.3573 - dense_3_accuracy: 0.2461 - dense_4_accuracy: 0.6979 - dense_5_accuracy: 0.9572 - dense_6_accuracy: 0.9997 - val_loss: 6.2845 - val_dense_1_loss: 0.8209 - val_dense_2_loss: 1.8738 - val_dense_3_loss: 2.1810 - val_dense_4_loss: 1.1241 - val_dense_5_loss: 0.2801 - val_dense_6_loss: 0.0048 - val_dense_1_accuracy: 0.6653 - val_dense_2_accuracy: 0.3332 - val_dense_3_accuracy: 0.2226 - val_dense_4_accuracy: 0.6972 - val_dense_5_accuracy: 0.9542 - val_dense_6_accuracy: 0.9999\n",
      "Epoch 21/100\n",
      "26716/26720 [============================>.] - ETA: 0s - loss: 6.7133 - dense_1_loss: 0.9401 - dense_2_loss: 1.9426 - dense_3_loss: 2.2505 - dense_4_loss: 1.2594 - dense_5_loss: 0.3118 - dense_6_loss: 0.0089 - dense_1_accuracy: 0.6423 - dense_2_accuracy: 0.3445 - dense_3_accuracy: 0.2351 - dense_4_accuracy: 0.6975 - dense_5_accuracy: 0.9572 - dense_6_accuracy: 0.9997\n",
      "Epoch 00021: saving model to my_model_whole.h5\n",
      "26720/26720 [==============================] - 246s 9ms/sample - loss: 6.7136 - dense_1_loss: 0.9402 - dense_2_loss: 1.9426 - dense_3_loss: 2.2505 - dense_4_loss: 1.2594 - dense_5_loss: 0.3120 - dense_6_loss: 0.0089 - dense_1_accuracy: 0.6424 - dense_2_accuracy: 0.3445 - dense_3_accuracy: 0.2351 - dense_4_accuracy: 0.6975 - dense_5_accuracy: 0.9571 - dense_6_accuracy: 0.9997 - val_loss: 6.2257 - val_dense_1_loss: 0.7939 - val_dense_2_loss: 1.8501 - val_dense_3_loss: 2.1638 - val_dense_4_loss: 1.1345 - val_dense_5_loss: 0.2790 - val_dense_6_loss: 0.0050 - val_dense_1_accuracy: 0.6764 - val_dense_2_accuracy: 0.3553 - val_dense_3_accuracy: 0.2278 - val_dense_4_accuracy: 0.6981 - val_dense_5_accuracy: 0.9543 - val_dense_6_accuracy: 0.9999\n",
      "Epoch 22/100\n",
      "26716/26720 [============================>.] - ETA: 0s - loss: 6.7657 - dense_1_loss: 0.9460 - dense_2_loss: 1.9709 - dense_3_loss: 2.2510 - dense_4_loss: 1.2691 - dense_5_loss: 0.3194 - dense_6_loss: 0.0093 - dense_1_accuracy: 0.6390 - dense_2_accuracy: 0.3334 - dense_3_accuracy: 0.2342 - dense_4_accuracy: 0.6983 - dense_5_accuracy: 0.9572 - dense_6_accuracy: 0.9997\n",
      "Epoch 00022: saving model to my_model_whole.h5\n",
      "26720/26720 [==============================] - 248s 9ms/sample - loss: 6.7660 - dense_1_loss: 0.9460 - dense_2_loss: 1.9708 - dense_3_loss: 2.2510 - dense_4_loss: 1.2692 - dense_5_loss: 0.3196 - dense_6_loss: 0.0093 - dense_1_accuracy: 0.6390 - dense_2_accuracy: 0.3334 - dense_3_accuracy: 0.2342 - dense_4_accuracy: 0.6983 - dense_5_accuracy: 0.9572 - dense_6_accuracy: 0.9997 - val_loss: 6.4154 - val_dense_1_loss: 0.8321 - val_dense_2_loss: 1.9491 - val_dense_3_loss: 2.1828 - val_dense_4_loss: 1.1728 - val_dense_5_loss: 0.2743 - val_dense_6_loss: 0.0050 - val_dense_1_accuracy: 0.6608 - val_dense_2_accuracy: 0.3071 - val_dense_3_accuracy: 0.2190 - val_dense_4_accuracy: 0.6972 - val_dense_5_accuracy: 0.9542 - val_dense_6_accuracy: 0.9999\n",
      "Epoch 23/100\n",
      "26716/26720 [============================>.] - ETA: 0s - loss: 6.8343 - dense_1_loss: 0.9596 - dense_2_loss: 2.0030 - dense_3_loss: 2.2693 - dense_4_loss: 1.2743 - dense_5_loss: 0.3186 - dense_6_loss: 0.0096 - dense_1_accuracy: 0.6327 - dense_2_accuracy: 0.3242 - dense_3_accuracy: 0.2260 - dense_4_accuracy: 0.6976 - dense_5_accuracy: 0.9572 - dense_6_accuracy: 0.9997\n",
      "Epoch 00023: saving model to my_model_whole.h5\n",
      "26720/26720 [==============================] - 250s 9ms/sample - loss: 6.8345 - dense_1_loss: 0.9596 - dense_2_loss: 2.0030 - dense_3_loss: 2.2693 - dense_4_loss: 1.2745 - dense_5_loss: 0.3186 - dense_6_loss: 0.0096 - dense_1_accuracy: 0.6327 - dense_2_accuracy: 0.3241 - dense_3_accuracy: 0.2260 - dense_4_accuracy: 0.6976 - dense_5_accuracy: 0.9572 - dense_6_accuracy: 0.9997 - val_loss: 6.5624 - val_dense_1_loss: 0.8754 - val_dense_2_loss: 1.9834 - val_dense_3_loss: 2.2273 - val_dense_4_loss: 1.1772 - val_dense_5_loss: 0.2954 - val_dense_6_loss: 0.0043 - val_dense_1_accuracy: 0.6393 - val_dense_2_accuracy: 0.2934 - val_dense_3_accuracy: 0.2058 - val_dense_4_accuracy: 0.6963 - val_dense_5_accuracy: 0.9543 - val_dense_6_accuracy: 0.9999\n",
      "Epoch 24/100\n",
      "26716/26720 [============================>.] - ETA: 0s - loss: 6.8193 - dense_1_loss: 0.9605 - dense_2_loss: 2.0048 - dense_3_loss: 2.2705 - dense_4_loss: 1.2650 - dense_5_loss: 0.3094 - dense_6_loss: 0.0092 - dense_1_accuracy: 0.6281 - dense_2_accuracy: 0.3151 - dense_3_accuracy: 0.2211 - dense_4_accuracy: 0.6965 - dense_5_accuracy: 0.9571 - dense_6_accuracy: 0.9997\n",
      "Epoch 00024: saving model to my_model_whole.h5\n",
      "26720/26720 [==============================] - 250s 9ms/sample - loss: 6.8195 - dense_1_loss: 0.9605 - dense_2_loss: 2.0048 - dense_3_loss: 2.2705 - dense_4_loss: 1.2649 - dense_5_loss: 0.3096 - dense_6_loss: 0.0092 - dense_1_accuracy: 0.6280 - dense_2_accuracy: 0.3150 - dense_3_accuracy: 0.2211 - dense_4_accuracy: 0.6965 - dense_5_accuracy: 0.9571 - dense_6_accuracy: 0.9997 - val_loss: 6.4911 - val_dense_1_loss: 0.8461 - val_dense_2_loss: 1.9842 - val_dense_3_loss: 2.2091 - val_dense_4_loss: 1.1504 - val_dense_5_loss: 0.2968 - val_dense_6_loss: 0.0048 - val_dense_1_accuracy: 0.6430 - val_dense_2_accuracy: 0.2848 - val_dense_3_accuracy: 0.2182 - val_dense_4_accuracy: 0.6960 - val_dense_5_accuracy: 0.9543 - val_dense_6_accuracy: 0.9999\n",
      "Epoch 25/100\n",
      "13044/26720 [=============>................] - ETA: 1:58 - loss: 6.8022 - dense_1_loss: 0.9446 - dense_2_loss: 2.0263 - dense_3_loss: 2.2584 - dense_4_loss: 1.2560 - dense_5_loss: 0.3044 - dense_6_loss: 0.0124 - dense_1_accuracy: 0.6294 - dense_2_accuracy: 0.3119 - dense_3_accuracy: 0.2242 - dense_4_accuracy: 0.6941 - dense_5_accuracy: 0.9571 - dense_6_accuracy: 0.9996- ETA: 2:08 - loss: 6.7835 - dense_1_loss: 0.9385 - dense_2_loss: 2.0201 - dense_3_loss: 2.2602 - dense_4_loss: 1.2570 - dense_5_loss: 0.2941 - dense_6_loss: 0.0137 - de\n",
      "Epoch 00025: saving model to my_model_whole.h5\n",
      "13044/26720 [=============>................] - ETA: 1:58 - loss: 6.8022 - dense_1_loss: 0.9446 - dense_2_loss: 2.0263 - dense_3_loss: 2.2584 - dense_4_loss: 1.2560 - dense_5_loss: 0.3044 - dense_6_loss: 0.0124 - dense_1_accuracy: 0.6294 - dense_2_accuracy: 0.3119 - dense_3_accuracy: 0.2242 - dense_4_accuracy: 0.6941 - dense_5_accuracy: 0.9571 - dense_6_accuracy: 0.9996"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-56410035a7ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m                     \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                     \u001b[0mvalidation_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m                     callbacks = [saved_model, tensorboard])\n\u001b[0m",
      "\u001b[1;32md:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32md:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    570\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    570\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36m_non_none_constant_value\u001b[1;34m(v)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_non_none_constant_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m   \u001b[0mconstant_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant_value\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mconstant_value\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\tensor_util.py\u001b[0m in \u001b[0;36mconstant_value\u001b[1;34m(tensor, partial)\u001b[0m\n\u001b[0;32m    820\u001b[0m   \"\"\"\n\u001b[0;32m    821\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 822\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    823\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    940\u001b[0m     \"\"\"\n\u001b[0;32m    941\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    906\u001b[0m     \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 908\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    909\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    910\u001b[0m       \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 执行训练与验证\n",
    "history = model.fit(train_images, train_labels, \n",
    "                    batch_size = 4, epochs = 100,\n",
    "                    validation_split = 0.2,\n",
    "                    callbacks = [saved_model, tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('my_model_whole.h5')\n",
    "correct = 0\n",
    "test_len = len(test_images)\n",
    "for i in range(test_len):\n",
    "    x = tf.expand_dims(test_images[i], axis=0)\n",
    "    y0 = tf.expand_dims(test_labels[0][i], axis=0)\n",
    "    y1 = tf.expand_dims(test_labels[1][i], axis=0)\n",
    "    y2 = tf.expand_dims(test_labels[2][i], axis=0)\n",
    "    y3 = tf.expand_dims(test_labels[3][i], axis=0)\n",
    "    y4 = tf.expand_dims(test_labels[4][i], axis=0)\n",
    "    y5 = tf.expand_dims(test_labels[5][i], axis=0)\n",
    "    y = [y0, y1, y2, y3, y4, y5]\n",
    "\n",
    "#     print(y)\n",
    "    val = model.evaluate(x, y,verbose=0)\n",
    "#     print(val)\n",
    "    acc = tf.reduce_prod(val[7:])\n",
    "    \n",
    "    if acc == 1:\n",
    "        correct += 1\n",
    "\n",
    "accuracy = correct / test_len\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
